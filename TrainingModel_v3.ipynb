{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## DATA SPLITTING/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bb85e27b73f7a2e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (columns) in the dataset: 85\n",
      " Label\n",
      "DDoS      128027\n",
      "BENIGN     97718\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Load the original CSV file\n",
    "    file_path = \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\" \n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Get the number of features (columns) in the dataset\n",
    "    num_features = data.shape[1]\n",
    "    print(f\"Number of features (columns) in the dataset: {num_features}\")\n",
    "    \n",
    "    # Count the occurrences of each class in the label column\n",
    "    label_counts = data[' Label'].value_counts()\n",
    "    print(label_counts)\n",
    "    \n",
    "    # # Shuffle the dataset (optional, but recommended if the data is ordered)\n",
    "    # data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    # \n",
    "    # # Split the data into 90% and 10%\n",
    "    # split_ratio = 0.9\n",
    "    # split_index = int(len(data) * split_ratio)\n",
    "    # \n",
    "    # data_90 = data[:split_index]  # First 90%\n",
    "    # data_10 = data[split_index:]  # Remaining 10%\n",
    "    # \n",
    "    # # Save the split data to separate CSV files\n",
    "    # data_90.to_csv(\"Training_2.csv\", index=False)  # Save 90% to a file\n",
    "    # data_10.to_csv(\"Testing_2.csv\", index=False)  # Save 10% to a file\n",
    "    # \n",
    "    # print(\"Data successfully split into Training.csv (90%) and Testing.csv (10%).\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {file_path} was not found. Please check the path and try again\")\n",
    "except PermissionError:\n",
    "    print(\"Error: Permission denied. Please check the path and try again\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred {e}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T21:04:04.201573900Z",
     "start_time": "2024-11-24T21:04:02.308801200Z"
    }
   },
   "id": "5c7e919bbc879c02",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CLEAN MODEL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eef0b7a9526f67c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RANDOM FOREST CLASSIFIER\n",
    "#### Implementation for training, evaluating, and analyzing the performance of a Random Forest for network traffic classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "965febab17af6b7d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index([], dtype='object')\n",
      "Cross-validation scores: [0.99988187 0.99994094 0.99992617]\n",
      "Mean cross-validation score: 0.9999163263988429\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy: 0.9999\n",
      "\n",
      "Classification Report (Test Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34955\n",
      "           1       1.00      1.00      1.00     46313\n",
      "\n",
      "    accuracy                           1.00     81268\n",
      "   macro avg       1.00      1.00      1.00     81268\n",
      "weighted avg       1.00      1.00      1.00     81268\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = \"Training_2.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "data[' Label'] = label_encoder.fit_transform(data[' Label'])\n",
    "\n",
    "# # Visualize feature importances to check which column to drop\n",
    "# importances = rf_classifier.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# features = data.drop([' Label'], axis=1).columns\n",
    "# \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.title(\"Feature Importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), features[indices], rotation=90)\n",
    "# plt.xlabel(\"Feature\")\n",
    "# plt.ylabel(\"Importance\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Identify and drop high-cardinality non-numeric columns\n",
    "columns_to_drop = ['Flow ID', ' Source IP', ' Destination IP', ' Timestamp']\n",
    "data = data.drop(columns=columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "# Identify remaining non-numeric columns\n",
    "non_numeric_columns = data.select_dtypes(include=['object']).columns\n",
    "print(f\"Non-numeric columns: {non_numeric_columns}\")\n",
    "\n",
    "# Encode remaining non-numeric columns if they exist\n",
    "if len(non_numeric_columns) > 0:\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_features = encoder.fit_transform(data[non_numeric_columns])\n",
    "    \n",
    "    # Drop the original non-numeric columns and append the encoded features\n",
    "    X = data.drop([' Label'] + list(non_numeric_columns), axis=1).values\n",
    "    X = np.hstack((X, encoded_features))\n",
    "else:\n",
    "    # If no non-numeric columns, proceed normally\n",
    "    X = data.drop([' Label'], axis=1).values\n",
    "\n",
    "# Handle infinity values and NaN\n",
    "X = data.drop([' Label'] + list(non_numeric_columns), axis=1).values\n",
    "X = np.where(np.isinf(X), np.nan, X)  # Replace infinity with NaN\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace NaN with feature mean\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Separate labels\n",
    "y = data[' Label'].values\n",
    "\n",
    "# Instantiate the Random Forest model with class_weight balanced\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Cross-validation to verify the impact of class_weight\n",
    "cv_scores = cross_val_score(rf_classifier, X, y, cv=3, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Fit the Random Forest model to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = rf_classifier.predict(X_train)\n",
    "y_pred_test = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "#generate a confusion matrix to see the performance\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T03:53:26.829581500Z",
     "start_time": "2024-11-24T03:51:04.464333900Z"
    }
   },
   "id": "4adb6108b543f359",
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
